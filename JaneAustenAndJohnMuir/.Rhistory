install.packages("RQDA")
install.packages("RQDA")
library(RQDA)
library(RQDA)
RQDA()
load("E:/Doctorate/DS7003/datasetVictorianAuthorshipAttribution/dataset/.RData")
View(hahacombineTwoListsAsOne)
View(hahacombineTwoListsAsOne)
View(hahacombineTwoListsAsOne)
View(combineTwoListsAsOne)
View(combineTwoListsAsOne)
View(combineTwoListsAsOne)
View(combineTwoListsAsOne)
i = 'umm'
haha = 'shall i comparing you to summer's time'
haha = "shall i comparing you to summer's time"
length(grep('\\<\i\\>', haha))
length(grep('\\<'i'\\>', haha))
length(grep(paste('\\<'i'\\>'), haha))
length(grep(paste('\\<',i,'\\>'), haha))
i = comparing
i = 'comparing'
length(grep(paste('\\<',i,'\\>'), haha))
length(grep('\\<comparing\\>', haha))
length(grep(paste('\\<',i,'\\>', sep =''), haha))
gsub('[[:punct]][:blank:]+', ' ', haha)
gsub('[[:punct][:blank:]]+', ' ', haha)
gsub('[[:punct:][:blank:]]+, ' ', haha)
)
gsub('[[:punct:][:blank:]]+', ' ', haha)
snnt18 = read.table(file.choose(), sep = ('|'))
snnt18
snnt18 = read.table(file.choose(), sep = ('|'))
snnt18 = read.table(file.choose(), sep = ('|'))
snnt18
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\snnt18.csv'
, sep = ('|'))
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\snnt18.csv'
, sep = ('|'))
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\snnt18.csv'
, sep = ('|'))
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\snnt18.csv'
, sep = ('|'))
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\snnt18.csv'
, sep = ('|'))
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\haha.csv'
, sep = ('|'))
)
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\haha.csv', sep = ('|'))
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\haha.csv', sep = ('|'))
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\haha.csv', sep = ('|'))
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\haha.csv', sep = ('|'))
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\snnt18.csv', sep = ('|'))
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\snnt18.csv', sep = ('|'))
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\snnt18.csv', sep = ('|'))
snnt18
str(snnt18)
str(haha)
snnt18 = read.table('E:\\Doctorate\\DS7003\\datasetVictorianAuthorshipAttribution\\dataset\\snnt18.csv', header = TRUE, sep = ('|'))
snnt18
str(snnt18)
setwd(dirname(file.access()))
load("F:/Doctorate/CN8001/RQDAWorkingFolder/.RData")
quit()
install.packages("RGtk2")
install.packages("RQDA", dependencies = TRUE)
library(RQDA)
library(RQDA)
#3 hours to run!
#if open this code to RStudio. After opened it,
#select File -> Reopen with Encoding -> UTF-8
#Reason: need to recognised the 'a head(caret)' symbol
setwd(dirname(file.choose()))
getwd()
dfVictorianEraAA <- read.table('Gungor_2018_VictorianAuthorAttribution_data_train.csv', header = TRUE, sep = (','))
dfJaneAusten26674_27073 <- dfVictorianEraAA[26674:27073,]
dfJaneAusten26674_27073$textNo <- rep(1:100, each = 4)
dfJaneAusten26674_27073 <- dfJaneAusten26674_27073[c('textNo', 'text')]
write.table(dfJaneAusten26674_27073, 'dfJaneAusten26674_27073.csv', quote = FALSE, sep = ',', row.names = FALSE)
dfJohnMuir31420_31819 <- dfVictorianEraAA[31420:31819,]
dfJohnMuir31420_31819$textNo <- rep(1:100, each = 4)
dfJohnMuir31420_31819 <- dfJohnMuir31420_31819[c('textNo', 'text')]
write.table(dfJohnMuir31420_31819, 'dfJohnMuir31420_31819.csv', quote = FALSE, sep = ',', row.names = FALSE)
combineTwoListsAsOne <- function (list1, list2) {
n <- c()
for(x in list1){n<-c(n,x)}
for(x in list2){n<-c(n,x)}
return(n)
}
library(tokenizers)
listOfWordsJaneAusten26674_27073 <- tokenize_words(paste0(dfJaneAusten26674_27073[1,2]))
for (i in 2:400) {
listOfWordsJaneAusten26674_27073 <- combineTwoListsAsOne (listOfWordsJaneAusten26674_27073, tokenize_words(paste0(dfJaneAusten26674_27073[i,2])))
listOfWordsJaneAusten26674_27073 <- unique(listOfWordsJaneAusten26674_27073)
}
listOfWordsJohnMuir31420_31819 <- tokenize_words(paste0(dfJohnMuir31420_31819[1,2]))
for (i in 2:400) {
listOfWordsJohnMuir31420_31819 <- combineTwoListsAsOne (listOfWordsJohnMuir31420_31819, tokenize_words(paste0(dfJohnMuir31420_31819[i,2])))
listOfWordsJohnMuir31420_31819 <- unique(listOfWordsJohnMuir31420_31819)
}
listOfWordsAppearingInBothJAAndJM <- Reduce(intersect, list(listOfWordsJaneAusten26674_27073,listOfWordsJohnMuir31420_31819))
A = function(x, y) {       #it works!
df <- data.frame('word' = 0)
for(i in x) {
num = 0
for(val in 1: nrow(y)) {
tokenized = tokenize_words(paste0(y[val,2]))
tokenized = unlist(tokenized, use.names=FALSE)
num = num + length(grep(paste('\\<',i,'\\>', sep =''), tokenized))
}
df[paste(i)] <- c(num)
}
return(df)
}
JA_NoOfWdsInJAnJMUniqWdLst = A(listOfWordsAppearingInBothJAAndJM, dfJaneAusten26674_27073)
JM_NoOfWdsInJAnJMUniqWdLst = A(listOfWordsAppearingInBothJAAndJM, dfJohnMuir31420_31819)
JAnJMJoin_NoOfWdsInJAnJMUniqWdLst = rbind(JA_NoOfWdsInJAnJMUniqWdLst, JM_NoOfWdsInJAnJMUniqWdLst)
JaJmTtl400OrMore = JAnJMJoin_NoOfWdsInJAnJMUniqWdLst[, colSums(JAnJMJoin_NoOfWdsInJAnJMUniqWdLst) >=400]
JaJmTtl400OrMoreByAlpha = JaJmTtl400OrMore[,order(names(JaJmTtl400OrMore))]#ok
JaJmTtl400OrMoreByAlpha = JaJmTtl400OrMoreByAlpha[-c(2)] # deleting a head
JaJmTtl400OrMoreByAlphaHeader = colnames(JaJmTtl400OrMoreByAlpha) # a list of 230 words
#remove <- c('e', 'f', 'h', 'j', 'l', 'n', 'o', 'r', 'u', 'v')
#JaJmTtl400OrMoreByAlphaHeader = setdiff(JaJmTtl400OrMoreByAlphaHeader, remove)
######################################################
#Draft: (produce df of word list for each text)
#A = function(x, y) {
#for(k in y)
#df <- data.frame('a' = 0)
#for(i in x) {
#num = 0
#for(val in 1: nrow(y)) {
#tokenized = tokenize_words(paste0(y[val,2]))
#tokenized = unlist(tokenized, use.names=FALSE)
#num = num + length(grep(paste('\\<',i,'\\>', sep =''), tokenized))
#}
#df[paste(i)] <- c(num)
#}
#return(df)
#}
###############################################
#Formed the JA and JM wordDf (220 x 200)
JaJmTtl400OrMoreByAlphaHeader = colnames(JaJmTtl400OrMoreByAlpha)#ok
remove <- c('Ã¢', 'e', 'f', 'h', 'j', 'l', 'n', 'o', 'r', 'u', 'v')#ok
JaJmTtl400OrMoreByAlphaHeader = setdiff(JaJmTtl400OrMoreByAlphaHeader, remove)#ok
dfEach4RWdNoOfOccu = function (x, y, z) {
for (i in 5: nrow(y)) {
if (i%%4 == 1) {
df <- y[i,]
}
else if (i%%4 != 0) {
df <- rbind(df, y[i,])
}
else {
df <- rbind(df, y[i,])
z = rbind(z, A(x, df))
}}
return(z)
}#ok
dfJaWdFeqDf = A(JaJmTtl400OrMoreByAlphaHeader, dfJaneAusten26674_27073[1:4,])
dfJaWdFeqDf = dfEach4RWdNoOfOccu(JaJmTtl400OrMoreByAlphaHeader, dfJaneAusten26674_27073, dfJaWdFeqDf)
dfJmWdFeqDf = A(JaJmTtl400OrMoreByAlphaHeader, dfJohnMuir31420_31819[1:4,])
dfJmWdFeqDf = dfEach4RWdNoOfOccu(JaJmTtl400OrMoreByAlphaHeader, dfJohnMuir31420_31819, dfJmWdFeqDf)#ok
dfJaAndJmWdFeqDf <= rbind(dfJaWdFeqDf, dfJmWdFeqDf)#ok
#code for preparing the above code by using the small snnt18.csv file
#snnt18WLst = c('a', 'summer', 'the', 'i', 'and')
#dfSnnt18WdFeqDf = A(snnt18WLst, snnt18Ed[1:4,])
#haha = dfEach4RWdNoOfOccu(snnt18WLst, snnt18Ed, dfSnnt18WdFeqDf)
#####################################################
Add label column to the beginning:
dfJaAndJmWdFeqDf$JAOrJM = c(rep('JA', 100), rep('JM', 100))
dfJaAndJmWdFeqDfLabled = dfJaAndJmWdFeqDf[,c(221,1:220)]#ok
#####################################################
#shuffling rows:
set.seed(12345)
rrowNos <- sample(nrow(dfJaAndJmWdFeqDfLabled))
dfJaAndJmWdFeqDfLabledRandm <- dfJaAndJmWdFeqDfLabled[rrowNos,]#ok
##################################################
#normalisation of columns
data_norm <- function(x) {(x- min(x))/ (max(x)- min(x))}
dfJaAndJmWdFeqDfLabledRandm_norm <- as.data.frame(lapply(dfJaAndJmWdFeqDfLabledRandm[,-1], data_norm))#ok
####################################################
#KNN!
library(class)
dfJaAndJmWdFeqDfLabledRandm_norm_train <- dfJaAndJmWdFeqDfLabledRandm_norm[1:160,]
dfJaAndJmWdFeqDfLabledRandm_norm_test <- dfJaAndJmWdFeqDfLabledRandm_norm[161:200,]
JaOrJm_pred <- knn(dfJaAndJmWdFeqDfLabledRandm_norm_train, dfJaAndJmWdFeqDfLabledRandm_norm_test, dfJaAndJmWdFeqDfLabledRandm[1:160,1], k= 13)
table(JaOrJm_pred, dfJaAndJmWdFeqDfLabledRandm[161:200,1])#ok
dfJaAndJmWdFeqDf <- rbind(dfJaWdFeqDf, dfJmWdFeqDf)#ok
#code for preparing the above code by using the small snnt18.csv file
#snnt18WLst = c('a', 'summer', 'the', 'i', 'and')
#dfSnnt18WdFeqDf = A(snnt18WLst, snnt18Ed[1:4,])
#haha = dfEach4RWdNoOfOccu(snnt18WLst, snnt18Ed, dfSnnt18WdFeqDf)
#####################################################
Add label column to the beginning:
dfJaAndJmWdFeqDf$JAOrJM = c(rep('JA', 100), rep('JM', 100))
dfJaAndJmWdFeqDfLabled = dfJaAndJmWdFeqDf[,c(221,1:220)]#ok
#####################################################
#shuffling rows:
set.seed(12345)
rrowNos <- sample(nrow(dfJaAndJmWdFeqDfLabled))
dfJaAndJmWdFeqDfLabledRandm <- dfJaAndJmWdFeqDfLabled[rrowNos,]#ok
##################################################
#normalisation of columns
data_norm <- function(x) {(x- min(x))/ (max(x)- min(x))}
dfJaAndJmWdFeqDfLabledRandm_norm <- as.data.frame(lapply(dfJaAndJmWdFeqDfLabledRandm[,-1], data_norm))#ok
####################################################
#KNN!
library(class)
dfJaAndJmWdFeqDfLabledRandm_norm_train <- dfJaAndJmWdFeqDfLabledRandm_norm[1:160,]
dfJaAndJmWdFeqDfLabledRandm_norm_test <- dfJaAndJmWdFeqDfLabledRandm_norm[161:200,]
JaOrJm_pred <- knn(dfJaAndJmWdFeqDfLabledRandm_norm_train, dfJaAndJmWdFeqDfLabledRandm_norm_test, dfJaAndJmWdFeqDfLabledRandm[1:160,1], k= 13)
table(JaOrJm_pred, dfJaAndJmWdFeqDfLabledRandm[161:200,1])#ok
dfJaAndJmWdFeqDf <- rbind(dfJaWdFeqDf, dfJmWdFeqDf)#ok
#####################################################
Add label column to the beginning:
dfJaAndJmWdFeqDf$JAOrJM = c(rep('JA', 100), rep('JM', 100))
dfJaAndJmWdFeqDfLabled = dfJaAndJmWdFeqDf[,c(221,1:220)]#ok
#####################################################
#shuffling rows:
set.seed(12345)
rrowNos <- sample(nrow(dfJaAndJmWdFeqDfLabled))
dfJaAndJmWdFeqDfLabledRandm <- dfJaAndJmWdFeqDfLabled[rrowNos,]#ok
##################################################
#normalisation of columns
data_norm <- function(x) {(x- min(x))/ (max(x)- min(x))}
dfJaAndJmWdFeqDfLabledRandm_norm <- as.data.frame(lapply(dfJaAndJmWdFeqDfLabledRandm[,-1], data_norm))#ok
####################################################
#KNN!
library(class)
dfJaAndJmWdFeqDfLabledRandm_norm_train <- dfJaAndJmWdFeqDfLabledRandm_norm[1:160,]
dfJaAndJmWdFeqDfLabledRandm_norm_test <- dfJaAndJmWdFeqDfLabledRandm_norm[161:200,]
JaOrJm_pred <- knn(dfJaAndJmWdFeqDfLabledRandm_norm_train, dfJaAndJmWdFeqDfLabledRandm_norm_test, dfJaAndJmWdFeqDfLabledRandm[1:160,1], k= 13)
JaOrJm_pred <- knn(dfJaAndJmWdFeqDfLabledRandm_norm_train, dfJaAndJmWdFeqDfLabledRandm_norm_test, dfJaAndJmWdFeqDfLabledRandm[1:160,1], k= 13)
View(dfJaAndJmWdFeqDfLabledRandm_norm_train)
View(dfJaAndJmWdFeqDfLabledRandm_norm)
View(dfJaAndJmWdFeqDfLabled)
dfJaAndJmWdFeqDf <- rbind(dfJaWdFeqDf, dfJmWdFeqDf)
dfJaAndJmWdFeqDf$JAOrJM = c(rep('JA', 100), rep('JM', 100))
dfJaAndJmWdFeqDfLabled = dfJaAndJmWdFeqDf[,c(221,1:220)]
view(dfJaAndJmWdFeqDfLabled)
View(dfJaAndJmWdFeqDfLabled)
dfJaAndJmWdFeqDf <- rbind(dfJaWdFeqDf, dfJmWdFeqDf)
View(dfJaAndJmWdFeqDf)
dfJaAndJmWdFeqDf$word <- NULL
dfJaAndJmWdFeqDf$JAOrJM = c(rep('JA', 100), rep('JM', 100))
dfJaAndJmWdFeqDfLabled = dfJaAndJmWdFeqDf[,c(221,1:220)]
View(dfJaAndJmWdFeqDfLabled)
set.seed(12345)
rrowNos <- sample(nrow(dfJaAndJmWdFeqDfLabled))
dfJaAndJmWdFeqDfLabledRandm <- dfJaAndJmWdFeqDfLabled[rrowNos,]
data_norm <- function(x) {(x- min(x))/ (max(x)- min(x))}
dfJaAndJmWdFeqDfLabledRandm_norm <- as.data.frame(lapply(dfJaAndJmWdFeqDfLabledRandm[,-1], data_norm))
library(class)
dfJaAndJmWdFeqDfLabledRandm_norm_train <- dfJaAndJmWdFeqDfLabledRandm_norm[1:160,]
dfJaAndJmWdFeqDfLabledRandm_norm_test <- dfJaAndJmWdFeqDfLabledRandm_norm[161:200,]
JaOrJm_pred <- knn(dfJaAndJmWdFeqDfLabledRandm_norm_train, dfJaAndJmWdFeqDfLabledRandm_norm_test, dfJaAndJmWdFeqDfLabledRandm[1:160,1], k= 13)
table(JaOrJm_pred, dfJaAndJmWdFeqDfLabledRandm[161:200,1])
A = function(x, y) {
for(k in y)
df <- data.frame('a' = 0)
for(i in x) {
num = 0
for(val in 1: nrow(y)) {
tokenized = tokenize_words(paste0(y[val,2]))
tokenized = unlist(tokenized, use.names=FALSE)
num = num + length(grep(paste('\\<',i,'\\>', sep =''), tokenized))
}
df[paste(i)] <- c(num)
}
return(df)
}
JA_NoOfWdsInJAnJMUniqWdLst = A(listOfWordsAppearingInBothJAAndJM, dfJaneAusten26674_27073)
JM_NoOfWdsInJAnJMUniqWdLst = A(listOfWordsAppearingInBothJAAndJM, dfJohnMuir31420_31819)
rm (list = ls())
getwd()
#Jane Austen vs John Muir. Each 400 lines x 1000 words divided into 100 documents.
#so each document 4000 words and total 200 documents
#set working directory and load package tm
setwd(dirname(file.choose()))
getwd()
library(tm)
#input data and form two dataframes
dfVictorianEraAA <- read.table('Gungor_2018_VictorianAuthorAttribution_data_train.csv', header = TRUE, sep = (','))
dfJA26674_27073 <- dfVictorianEraAA[26674:27073,]
dfJM31420_31819 <- dfVictorianEraAA[31420:31819,]
#form corpa with dataframes. Texts already cleaned
#package tm is required
JA26674_27073_corpus <- VCorpus(VectorSource(dfJA26674_27073$text))
JA26674_27073_corpus <- tm_map(JA26674_27073_corpus, stripWhitespace)
JM31420_31819_corpus <- VCorpus(VectorSource(dfJM31420_31819$text))
JM31420_31819_corpus <- tm_map(JM31420_31819_corpus, stripWhitespace)
#form dtm. Each line(1000 words) a document
#change minimum word length to 1 from 3
JA26674_27073_dtDf <- as.data.frame(as.matrix(DocumentTermMatrix(JA26674_27073_corpus, control=list(wordLengths = c(1, Inf)))))
JM31420_31819_dtDf <- as.data.frame(as.matrix(DocumentTermMatrix(JM31420_31819_corpus, control=list(wordLengths = c(1, Inf)))))
#retain column of words which can found from both JA and JM's texts only
common_cols <- intersect(colnames(JA26674_27073_dtDf), colnames(JM31420_31819_dtDf))
JAAndJMdtDf <- rbind(JA26674_27073_dtDf[common_cols], JM31420_31819_dtDf[common_cols])
#further retain columns of words each of which are at least appeared 400 times
#(i.e. 0.05% of the total number of words: 800000)
JAAndJMdtDf400OrMore <- JAAndJMdtDf[, colSums(JAAndJMdtDf) >=400]#231 columns
#delete single character columns (but not m: reason: i'm/ t: can't/ etc.)
JAAndJMdtDf400OrMore[ ,c('Ã¢', 'e', 'f', 'h', 'j', 'l', 'n', 'o', 'r', 'u', 'v')] <- list(NULL)#231 to 220
View(JAAndJMdtDf400OrMore)
str(JAAndJMdtDf400OrMore)
JAAndJMdtDf400OrMore$textNo <- rep(1:200, each = 4)
str(JAAndJMdtDf400OrMore)
View(JAAndJMdtDf400OrMore)
aggregate(. ~ textNo, JAAndJMdtDf400OrMore, sum)
dfJaAndJmWdFeqDf <- aggregate(. ~ textNo, JAAndJMdtDf400OrMore, sum)
View(dfJaAndJmWdFeqDf)
dfJaAndJmWdFeqDf$textNo <- NULL
summary(dfJaAndJmWdFeqDf)
str(dfJaAndJmWdFeqDf)
dfJaAndJmWdFeqDf$JAOrJM <- c(rep('JA', 100), rep('JM', 100))
dfJaAndJmWdFeqDfLabled <- dfJaAndJmWdFeqDf[,c(221,1:220)]
#shuffling rows:
set.seed(12345)
rrowNos <- sample(nrow(dfJaAndJmWdFeqDfLabled))
dfJaAndJmWdFeqDfLabledRandm <- dfJaAndJmWdFeqDfLabled[rrowNos,]#ok
#normalising columns
data_norm <- function(x) {(x- min(x))/ (max(x)- min(x))}
dfJaAndJmWdFeqDfLabledRandm_norm <- as.data.frame(lapply(dfJaAndJmWdFeqDfLabledRandm[,-1], data_norm))#ok
#KNN!
library(class)
dfJaAndJmWdFeqDfLabledRandm_norm_train <- dfJaAndJmWdFeqDfLabledRandm_norm[1:160,]
dfJaAndJmWdFeqDfLabledRandm_norm_test <- dfJaAndJmWdFeqDfLabledRandm_norm[161:200,]
JaOrJm_pred <- knn(dfJaAndJmWdFeqDfLabledRandm_norm_train, dfJaAndJmWdFeqDfLabledRandm_norm_test, dfJaAndJmWdFeqDfLabledRandm[1:160,1], k= 13)
#show cross table
table(JaOrJm_pred, dfJaAndJmWdFeqDfLabledRandm[161:200,1])
#aggreate and sum every four lines
JAAndJMdtDf400OrMore$textNo <- rep(1:200, each = 4)
dfJaAndJmWdFeqDf <- aggregate(. ~ textNo, JAAndJMdtDf400OrMore, sum)
dfJaAndJmWdFeqDf$textNo <- NULL
#add labels JA and JM
dfJaAndJmWdFeqDf$JAOrJM <- c(rep('JA', 100), rep('JM', 100))
dfJaAndJmWdFeqDfLabled <- dfJaAndJmWdFeqDf[,c(221,1:220)]
#shuffling rows:
set.seed(12345)
rrowNos <- sample(nrow(dfJaAndJmWdFeqDfLabled))
dfJaAndJmWdFeqDfLabledRandm <- dfJaAndJmWdFeqDfLabled[rrowNos,]#ok
#normalising columns
data_norm <- function(x) {(x- min(x))/ (max(x)- min(x))}
dfJaAndJmWdFeqDfLabledRandm_norm <- as.data.frame(lapply(dfJaAndJmWdFeqDfLabledRandm[,-1], data_norm))#ok
#KNN!
library(class)
dfJaAndJmWdFeqDfLabledRandm_norm_train <- dfJaAndJmWdFeqDfLabledRandm_norm[1:160,]
dfJaAndJmWdFeqDfLabledRandm_norm_test <- dfJaAndJmWdFeqDfLabledRandm_norm[161:200,]
JaOrJm_pred <- knn(dfJaAndJmWdFeqDfLabledRandm_norm_train, dfJaAndJmWdFeqDfLabledRandm_norm_test, dfJaAndJmWdFeqDfLabledRandm[1:160,1], k= 13)
#show cross table
table(JaOrJm_pred, dfJaAndJmWdFeqDfLabledRandm[161:200,1])
rm(list = ls())
